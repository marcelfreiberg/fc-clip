# python train_net.py --config-file configs/coco/panoptic-segmentation/fcclip/fcclip_convnext_large_train_lars_coco.yaml --num-gpus 8

_BASE_: ../maskformer2_R50_bs16_50ep.yaml

MODEL:
  WEIGHTS: "/data/mfreiberg/weights/fcclip/fcclip_cocopan.pth"
  META_ARCHITECTURE: "FCCLIP"
  SEM_SEG_HEAD:
    NAME: "FCCLIPHead"
    NUM_CLASSES: 11
  # backbone part.
  BACKBONE:
    NAME: "CLIP"
  FC_CLIP:
    CLIP_MODEL_NAME: "convnext_large_d_320"
    CLIP_PRETRAINED_WEIGHTS: "laion2b_s29b_b131k_ft_soup"
    EMBED_DIM: 768
    GEOMETRIC_ENSEMBLE_ALPHA: 0.4
    GEOMETRIC_ENSEMBLE_BETA: 0.8
  MASK_FORMER:
    NUM_OBJECT_QUERIES: 50
    TRAIN_NUM_POINTS: 4096
    TEST:
      SEMANTIC_ON: True
      PANOPTIC_ON: True
      INSTANCE_ON: False

# Training configuration
SOLVER:
  IMS_PER_BATCH: 8
  BASE_LR: 0.0001
  MAX_ITER: 8000
  LR_SCHEDULER_NAME: WarmupPolyLR
  WARMUP_ITERS: 500
  WEIGHT_DECAY: 2.0e-05
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CHECKPOINT_PERIOD: 500
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
  AMP:
    ENABLED: True

INPUT:
  DATASET_MAPPER_NAME: "coco_panoptic_lsj"
  IMAGE_SIZE: 384
  MIN_SCALE: 0.1
  MAX_SCALE: 1.5

DATASETS:
  TRAIN: ("lars_coco_train_panoptic",)
  TEST: ("lars_coco_val_panoptic",)

TEST:
  EVAL_PERIOD: 500  # same as checkpoint period

DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 2

OUTPUT_DIR: ./output/lars_coco_training